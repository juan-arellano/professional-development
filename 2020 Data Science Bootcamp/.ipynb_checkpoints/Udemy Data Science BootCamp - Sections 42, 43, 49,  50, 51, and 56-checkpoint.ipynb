{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 42\n",
    "Think of a machine learning model as a black box that you feed input and gives back an output. Before we get comfortable and confident about the model's output, we must train our model. This is the only way for our model to make sense of the input model. The basic logic for training an algorithm involves four components\n",
    "- Data\n",
    "- Model\n",
    "- Objective Function\n",
    "- Optimization Algorithm\n",
    "\n",
    "First, we must prepare a certain amount of data to train with. Second, we need a model. The simplest model we can train is a linear model. The linear model is just the tip of the iceberg. Third, is the objective function. The objective function estimates how accurate the models output is on average. We want to minimize the objective function. The fourth part is the optimization algorithm, it optimizes the different parameters in order to minimize the objective function. These are not four steps but four ingredients, because this process completely iterative. \n",
    "\n",
    "The machine learning process is a kind of a trial and error training. After thousands of trials and errors, the machine will eventually learn how to produce the proper output as expected by the user. Think of a self driving car. Self driving cars don't follow rules like don't hit curbs. They watch hours of videos of people driving and train themselves to drive. It's not about the rules but rather about the output. \n",
    "\n",
    "There are three major types of machine learning:\n",
    "- supervised: we provide the model with inputs and corresponding required outputs\n",
    "- unsupervised: we feed inputs but there are no target outputs\n",
    "- reinforcement: we would train our model to act in an environment based on the reward it receives\n",
    "\n",
    "Supervised learning is the focus of this course. It can be divided into two subtypes, classification and regression. We will create both classification and regression algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the variable x, we know that $f(x)$ is a linear function. The linear model is the basis for more complicated models. In the linear model universe, $f(x) = xw + b$ where $w$ is our weight and $b$ is our bias. The goal of the machine learning algorithm would be to find such values for w and b, so the output of $wx + b$ is as close to the observed values as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model works with multiple inputs. Say for instance we are calculating real estate price, we could simply have size as a variable to calculate price, but we could also add a variable for proximity to the beach. In this scenario, our formula would look something like $y = x_1*w_1 + x_2*w_2 + b$. We can have multiple inputs in our linear models and this would improve our accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we wanted to not only predict price, but also how much rent we could charge. Our inputs would be unchanged but this time we have two outputs, so we can create two linear models. We have the same number of inputs, but we have k * m weights, where m is the ouputs and k is the inputs. Each model is determined solely by its weights and biases. In ML, we vary only the weights and the biases, but the logic of the model remains the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the objective function? The objective function is the mesure used to evaluate how well the model's outputs match the observed ouptputs. There are two types of objective functions, loss functions and reward functions. Usually, reward functions are used more in reinforcement learning. When dealing with supervised learning, you are most likely going to be using loss functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is the desired value at which we are aiming, we want our output y to be as close to our target t. One common loss functions are the L2-norm in regression models. The lower the error between y and t, the the lower the loss. Norm comes from the fact it is the vector norm, or Euclidean distance of the outputs and the targets. Cross entropy is the common loss function for classification. It is defined as $L(y, t) = - \\sum t_i * \\ln{y}$. The lower the loss, the more accurate the model. There are also other loss functions. Any function that holds the basic property of higher for worse results, lower for better results can be a loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest optimization algorithm is the gradient descent. Imagine a function $f(x) = 5x^2 + 3x + 4$. Our goal is to find the minimum using the gradient descent methodology. First we find the first derivative $f'(x) = 10x + 3$. Then pick an arbitraty $x_0$ such as 4, then $x_{i + 1} = x_i - \\eta * f'(x_i)$. $x_1 = 4 - \\eta * [10*4 + 3] = 4 - \\eta * 43$. $\\eta$ is the learning rate. We choose the learning rate for each case. Using the update rule we can find $x_2, x_3,$ and so on. Generally, we want the learning rate to be: high enough so we can reach the closes minimum in a rational amount of time and low enough so we don't oscillate around the minimum. We can find the minimum by trial and error using gradient descent. Each trial is better than the previous one due to the update rule. We should stop updating once we've converged. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think back to the model: $wx + b = y$. A single observation $x_i*w + b = y_i$. We are interested in target $t_i$. Then we think of our loss function, $L(y, t) = \\frac{\\sum_i (y_i - t_i)^2}{2}$. To perform the gradient descent, our update rule is $x_{i + 1} = x_i - \\eta * f'(x_i)$ converted to $w_{i + 1} = w_i - \\eta * \\nabla_w * L(y,t)$ and $b_{i + 1} = b_i - \\eta * \\nabla_b * L(y,t)$. It is basically the same but for the matrices w and b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The course did not have a python example of gradient descent in this course so I found my own dataset \n",
    "# and implemented the gradient descent code found here: https://engmrk.com/gradient-descent/?utm_campaign=News&utm_medium=Community&utm_source=DataCamp.com\n",
    "# on my own found dataset on Kaggle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('~/Desktop/Salary_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearsExperience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>39343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3</td>\n",
       "      <td>46205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>37731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>43525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2</td>\n",
       "      <td>39891.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YearsExperience   Salary\n",
       "0              1.1  39343.0\n",
       "1              1.3  46205.0\n",
       "2              1.5  37731.0\n",
       "3              2.0  43525.0\n",
       "4              2.2  39891.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at 10 iteration =  1.0259787380427098e+28\n",
      "Cost at 20 iteration =  1.1146726468958901e+48\n",
      "Cost at 30 iteration =  1.2110339753319226e+68\n",
      "Cost at 40 iteration =  1.3157255571780599e+88\n",
      "Cost at 50 iteration =  1.429467526984158e+108\n",
      "Cost at 60 iteration =  1.553042273561059e+128\n",
      "Cost at 70 iteration =  1.6872998217429468e+148\n",
      "Cost at 80 iteration =  1.833163679392823e+168\n",
      "Cost at 90 iteration =  1.991637189870444e+188\n",
      "W =  1.9583023419349652e+103 & b =  2.906038689577634e+102\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df['YearsExperience']\n",
    "Y = df['Salary']\n",
    "\n",
    "costs = []\n",
    "#Step 1: Parameter initialization \n",
    "W = 0.45\n",
    "b = 0.75\n",
    "\n",
    "for i in range(1, 100):\n",
    "    \n",
    "#Step 2: Step 2: Calculate Cost\n",
    "    Y_pred = np.multiply(W, X) + b\n",
    "    Loss_error = 0.5 * (Y_pred - Y)**2\n",
    "    cost = np.sum(Loss_error)/10\n",
    "    \n",
    "#Step 3: Calculate dW and db    \n",
    "    db = np.sum((Y_pred - Y))\n",
    "    dw = np.dot((Y_pred - Y), X)\n",
    "    costs.append(cost)\n",
    "\n",
    "#Step 4: Update parameters:\n",
    "    W = W - 0.01*dw\n",
    "    b = b - 0.01*db\n",
    "    \n",
    "    if i%10 == 0:\n",
    "        print(\"Cost at\", i,\"iteration = \", cost)\n",
    "\n",
    "#Step 5: Repeat from Step, implemented as a for loop with 1000 iterations\n",
    "\n",
    "#Plot the cost against no. of iterations\n",
    "print(\"W = \", W,\"& b = \",  b)\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per tens)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 43 \n",
    "Simple linear regression - minimal example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Generate random data\n",
    "observations = 1000\n",
    "\n",
    "# Two variables of our linear model\n",
    "xs = np.random.uniform(low = -10, high = 10, size = (observations, 1))\n",
    "zs = np.random.uniform(-10, 10, (observations, 1))\n",
    "\n",
    "inputs = np.column_stack((xs,zs))\n",
    "\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create the targets we will aim at\n",
    "# Our targets should be equal to 2x - 3z + 5 + noise\n",
    "\n",
    "noise = np.random.uniform(-1, 1, (observations, 1))\n",
    "\n",
    "targets = 2*xs - 3*zs + 5 + noise\n",
    "\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training data\n",
    "targets = targets.reshape(observations,)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Choose the axes.\n",
    "ax.plot(xs, zs, targets)\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('xs')\n",
    "ax.set_ylabel('zs')\n",
    "ax.set_zlabel('Targets')\n",
    "\n",
    "\n",
    "ax.view_init(azim=100)\n",
    "\n",
    "plt.show()\n",
    "targets = targets.reshape(observations,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03544033]\n",
      " [-0.02938404]]\n",
      "[-0.00682997]\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "init_range = 0.1\n",
    "\n",
    "weights = np.random.uniform(-init_range, init_range, size = (2,1))\n",
    "\n",
    "biases = np.random.uniform(-init_range, init_range, size = 1)\n",
    "\n",
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate\n",
    "learning_rate = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240.39527608107986\n",
      "35.27787908204492\n",
      "13.989345554451653\n",
      "11.371625195078858\n",
      "10.707716766695714\n",
      "10.267622027809695\n",
      "9.866715234323756\n",
      "9.484114552682362\n",
      "9.116889225325979\n",
      "8.76417071650047\n",
      "8.425354954522223\n",
      "8.099889983078036\n",
      "7.787249201497752\n",
      "7.486927231997589\n",
      "7.198438673566559\n",
      "6.921317259880902\n",
      "6.655115097843349\n",
      "6.399401942593622\n",
      "6.153764501979791\n",
      "5.9178057685602\n",
      "5.691144377943763\n",
      "5.473413992415615\n",
      "5.264262708849818\n",
      "5.063352489951752\n",
      "4.870358617910942\n",
      "4.68496916958128\n",
      "4.506884512340404\n",
      "4.335816819813452\n",
      "4.171489606678446\n",
      "4.0136372818014765\n",
      "3.8620047189794415\n",
      "3.7163468445965373\n",
      "3.576428241528104\n",
      "3.4420227686515936\n",
      "3.3129131953497253\n",
      "3.188890850415115\n",
      "3.069755284788881\n",
      "2.955313947588187\n",
      "2.8453818748990636\n",
      "2.7397813908315505\n",
      "2.6383418203539857\n",
      "2.540899213442315\n",
      "2.447296080098585\n",
      "2.3573811358103405\n",
      "2.271009057039542\n",
      "2.188040246345808\n",
      "2.1083406067643655\n",
      "2.0317813250740517\n",
      "1.9582386636050833\n",
      "1.8875937602500992\n",
      "1.8197324363552465\n",
      "1.754545012180831\n",
      "1.6919261296332462\n",
      "1.6317745819817142\n",
      "1.5739931502845719\n",
      "1.5184884462607753\n",
      "1.4651707613526423\n",
      "1.41395392173587\n",
      "1.3647551490425354\n",
      "1.3174949265719227\n",
      "1.2720968707729716\n",
      "1.228487607790637\n",
      "1.186596654876604\n",
      "1.1463563064727227\n",
      "1.1077015247830155\n",
      "1.0705698346574162\n",
      "1.0349012226173557\n",
      "1.000638039859961\n",
      "0.9677249090841373\n",
      "0.9361086349879211\n",
      "0.9057381182924605\n",
      "0.8765642731536498\n",
      "0.8485399478279442\n",
      "0.821619848464142\n",
      "0.795760465897943\n",
      "0.7709200053309917\n",
      "0.7470583187807146\n",
      "0.7241368401918202\n",
      "0.7021185231045465\n",
      "0.6809677807789343\n",
      "0.6606504286783506\n",
      "0.6411336292192977\n",
      "0.6223858386982094\n",
      "0.6043767563094723\n",
      "0.5870772751722391\n",
      "0.5704594352869238\n",
      "0.5544963783453145\n",
      "0.5391623043212738\n",
      "0.5244324297718781\n",
      "0.5102829477815889\n",
      "0.49669098948471946\n",
      "0.4836345871040071\n",
      "0.4710926384455619\n",
      "0.45904487279279327\n",
      "0.44747181814420095\n",
      "0.4363547697420735\n",
      "0.4256757598412363\n",
      "0.41541752866898196\n",
      "0.4055634965292444\n",
      "0.3960977370059453\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for i in range (100):\n",
    "    outputs = np.dot(inputs, weights) + biases\n",
    "    deltas = outputs - targets\n",
    "    \n",
    "    # Follow the L2-norm loss formula divided by 2\n",
    "    # Division by a constant doesn't change the logic of the loss, as it is still lower for higher\n",
    "    # accuracy\n",
    "    loss = np.sum(deltas ** 2) / 2 / observations\n",
    "    \n",
    "    # Want to see the loss decrease after each iteration\n",
    "    print(loss)\n",
    "    \n",
    "    # Update the weights and the biases following the gradient descent logic\n",
    "    deltas_scaled = deltas / observations\n",
    "    weights = weights - learning_rate *np.dot(inputs.T, deltas_scaled)\n",
    "    biases = biases - learning_rate * np.sum(deltas_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.00957927]\n",
      " [-3.0005469 ]] [4.35180855]\n"
     ]
    }
   ],
   "source": [
    "# Print the weights and the biases\n",
    "print(weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot last outputs vs targets\n",
    "plt.plot(outputs, targets)\n",
    "plt.xlabel('outputs')\n",
    "plt.ylabel('targets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Salary dataset I found on my own:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearsExperience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>39343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3</td>\n",
       "      <td>46205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>37731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>43525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2</td>\n",
       "      <td>39891.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YearsExperience   Salary\n",
       "0              1.1  39343.0\n",
       "1              1.3  46205.0\n",
       "2              1.5  37731.0\n",
       "3              2.0  43525.0\n",
       "4              2.2  39891.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('~/Desktop/Salary_Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "inputs = df['YearsExperience']\n",
    "print(inputs.shape)\n",
    "\n",
    "targets = df['Salary']\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7025.81717744]\n",
      "[-0.04038826]\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "init_range = 0.1\n",
    "\n",
    "weights = np.random.uniform(0, 10000, size = 1)\n",
    "\n",
    "biases = np.random.uniform(-init_range, init_range, size = 1)\n",
    "\n",
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate\n",
    "learning_rate = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17888226.03431402\n",
      "17869205.960454848\n",
      "17850346.473958597\n",
      "17831646.218978718\n",
      "17813103.851116173\n",
      "17794718.03732272\n",
      "17776487.455805134\n",
      "17758410.79593011\n",
      "17740486.758130107\n",
      "17722714.053809915\n",
      "17705091.405253936\n",
      "17687617.54553444\n",
      "17670291.21842039\n",
      "17653111.178287167\n",
      "17636076.19002705\n",
      "17619185.02896036\n",
      "17602436.480747435\n",
      "17585829.341301393\n",
      "17569362.416701455\n",
      "17553034.523107212\n",
      "17536844.486673422\n",
      "17520791.143465728\n",
      "17504873.339376904\n",
      "17489089.930043895\n",
      "17473439.78076557\n",
      "17457921.76642113\n",
      "17442534.771389212\n",
      "17427277.6894677\n",
      "17412149.423794203\n",
      "17397148.886767197\n",
      "17382274.999967787\n",
      "17367526.694082268\n",
      "17352902.908825174\n",
      "17338402.592863075\n",
      "17324024.703738995\n",
      "17309768.20779751\n",
      "17295632.080110356\n",
      "17281615.304402784\n",
      "17267716.872980516\n",
      "17253935.786657296\n",
      "17240271.054683026\n",
      "17226721.694672536\n",
      "17213286.732535016\n",
      "17199965.202403944\n",
      "17186756.146567628\n",
      "17173658.615400415\n",
      "17160671.66729435\n",
      "17147794.368591554\n",
      "17135025.793517027\n",
      "17122365.024112176\n",
      "17109811.15016872\n",
      "17097363.26916334\n",
      "17085020.48619278\n",
      "17072781.913909476\n",
      "17060646.67245772\n",
      "17048613.889410596\n",
      "17036682.699707016\n",
      "17024852.24558971\n",
      "17013121.676543433\n",
      "17001490.149233926\n",
      "16989956.82744726\n",
      "16978520.882029615\n",
      "16967181.490827836\n",
      "16955937.838630207\n",
      "16944789.11710788\n",
      "16933734.52475678\n",
      "16922773.26683998\n",
      "16911904.55533052\n",
      "16901127.608854797\n",
      "16890441.652636405\n",
      "16879845.918440387\n",
      "16869339.64451804\n",
      "16858922.07555213\n",
      "16848592.462602623\n",
      "16838350.063052792\n",
      "16828194.14055588\n",
      "16818123.964982137\n",
      "16808138.812366292\n",
      "16798237.96485563\n",
      "16788420.710658222\n",
      "16778686.343991864\n",
      "16769034.165033298\n",
      "16759463.479867905\n",
      "16749973.600439835\n",
      "16740563.844502501\n",
      "16731233.53556957\n",
      "16721982.002866322\n",
      "16712808.581281364\n",
      "16703712.611318974\n",
      "16694693.439051487\n",
      "16685750.41607241\n",
      "16676882.899449797\n",
      "16668090.251679989\n",
      "16659371.840641791\n",
      "16650727.039551044\n",
      "16642155.226915572\n",
      "16633655.786490465\n",
      "16625228.10723381\n",
      "16616871.583262732\n",
      "16608585.613809867\n",
      "16600369.60318018\n",
      "16592222.96070805\n",
      "16584145.100714957\n",
      "16576135.442467226\n",
      "16568193.410134392\n",
      "16560318.432747692\n",
      "16552509.94415915\n",
      "16544767.383000754\n",
      "16537090.192644158\n",
      "16529477.821160667\n",
      "16521929.721281553\n",
      "16514445.35035866\n",
      "16507024.17032548\n",
      "16499665.64765842\n",
      "16492369.253338426\n",
      "16485134.462812996\n",
      "16477960.755958447\n",
      "16470847.617042523\n",
      "16463794.5346873\n",
      "16456801.00183248\n",
      "16449866.515698882\n",
      "16442990.577752285\n",
      "16436172.693667661\n",
      "16429412.373293553\n",
      "16422709.130616916\n",
      "16416062.48372808\n",
      "16409471.954786213\n",
      "16402937.069984883\n",
      "16396457.35951806\n",
      "16390032.357546262\n",
      "16383661.602163145\n",
      "16377344.635362264\n",
      "16371081.003004115\n",
      "16364870.254783547\n",
      "16358711.944197334\n",
      "16352605.628512101\n",
      "16346550.86873249\n",
      "16340547.22956964\n",
      "16334594.279409787\n",
      "16328691.590283351\n",
      "16322838.737834075\n",
      "16317035.30128864\n",
      "16311280.863426242\n",
      "16305575.010548752\n",
      "16299917.33245088\n",
      "16294307.422390766\n",
      "16288744.877060644\n",
      "16283229.296557898\n",
      "16277760.284356324\n",
      "16272337.447277619\n",
      "16266960.395463062\n",
      "16261628.742345573\n",
      "16256342.104621846\n",
      "16251100.102224806\n",
      "16245902.358296363\n",
      "16240748.4991602\n",
      "16235638.154294997\n",
      "16230570.956307745\n",
      "16225546.540907362\n",
      "16220564.546878489\n",
      "16215624.616055528\n",
      "16210726.393296873\n",
      "16205869.526459424\n",
      "16201053.666373232\n",
      "16196278.466816375\n",
      "16191543.584490154\n",
      "16186848.6789943\n",
      "16182193.4128026\n",
      "16177577.451238574\n",
      "16173000.462451437\n",
      "16168462.117392238\n",
      "16163962.089790171\n",
      "16159500.056129204\n",
      "16155075.695624704\n",
      "16150688.69020049\n",
      "16146338.7244659\n",
      "16142025.485693097\n",
      "16137748.66379467\n",
      "16133507.951301247\n",
      "16129303.043339463\n",
      "16125133.637609998\n",
      "16120999.434365852\n",
      "16116900.136390837\n",
      "16112835.44897814\n",
      "16108805.079909174\n",
      "16104808.739432586\n",
      "16100846.140243404\n",
      "16096916.997462375\n",
      "16093021.028615486\n",
      "16089157.9536137\n",
      "16085327.494732732\n",
      "16081529.376593193\n",
      "16077763.326140685\n",
      "16074029.072626263\n",
      "16070326.347586894\n",
      "16066654.884826234\n",
      "16063014.420395378\n",
      "16059404.692574015\n",
      "16055825.44185154\n",
      "16052276.410908382\n",
      "16048757.34459755\n",
      "16045267.989926277\n",
      "16041808.096037794\n",
      "16038377.414193409\n",
      "16034975.6977544\n",
      "16031602.702164568\n",
      "16028258.18493243\n",
      "16024941.905613907\n",
      "16021653.625794973\n",
      "16018393.109074583\n",
      "16015160.121047607\n",
      "16011954.429287992\n",
      "16008775.803332115\n",
      "16005624.01466212\n",
      "16002498.836689608\n",
      "15999400.044739174\n",
      "15996327.416032443\n",
      "15993280.729671935\n",
      "15990259.766625218\n",
      "15987264.309709178\n",
      "15984294.143574346\n",
      "15981349.05468952\n",
      "15978428.831326285\n",
      "15975533.263543932\n",
      "15972662.143174225\n",
      "15969815.263806524\n",
      "15966992.420772944\n",
      "15964193.411133604\n",
      "15961418.03366204\n",
      "15958666.088830778\n",
      "15955937.378796957\n",
      "15953231.70738811\n",
      "15950548.880088048\n",
      "15947888.704022907\n",
      "15945250.987947257\n",
      "15942635.542230396\n",
      "15940042.178842638\n",
      "15937470.711341847\n",
      "15934920.95486006\n",
      "15932392.726090113\n",
      "15929885.843272556\n",
      "15927400.126182524\n",
      "15924935.396116795\n",
      "15922491.475880954\n",
      "15920068.18977668\n",
      "15917665.363588989\n",
      "15915282.824573886\n",
      "15912920.401445867\n",
      "15910577.924365493\n",
      "15908255.224927416\n",
      "15905952.136148082\n",
      "15903668.492453782\n",
      "15901404.129668765\n",
      "15899158.885003436\n",
      "15896932.597042609\n",
      "15894725.105733963\n",
      "15892536.252376493\n",
      "15890365.879609108\n",
      "15888213.831399338\n",
      "15886079.95303208\n",
      "15883964.091098547\n",
      "15881866.093485137\n",
      "15879785.809362564\n",
      "15877723.089175008\n",
      "15875677.784629365\n",
      "15873649.748684557\n",
      "15871638.83554099\n",
      "15869644.90063006\n",
      "15867667.800603759\n",
      "15865707.393324392\n",
      "15863763.537854312\n",
      "15861836.094445828\n",
      "15859924.924531152\n",
      "15858029.890712434\n",
      "15856150.856751854\n",
      "15854287.687561847\n",
      "15852440.249195477\n",
      "15850608.408836627\n",
      "15848792.034790618\n",
      "15846990.996474655\n",
      "15845205.164408462\n",
      "15843434.410204953\n",
      "15841678.606561068\n",
      "15839937.6272485\n",
      "15838211.347104762\n",
      "15836499.642024083\n",
      "15834802.388948537\n",
      "15833119.465859175\n",
      "15831450.751767268\n",
      "15829796.126705563\n",
      "15828155.471719772\n",
      "15826528.668859862\n",
      "15824915.601171713\n",
      "15823316.152688617\n",
      "15821730.208423018\n",
      "15820157.65435817\n",
      "15818598.377440002\n",
      "15817052.265568942\n",
      "15815519.207591865\n",
      "15813999.093294177\n",
      "15812491.813391792\n",
      "15810997.259523297\n",
      "15809515.32424221\n",
      "15808045.90100921\n",
      "15806588.8841845\n",
      "15805144.169020195\n",
      "15803711.651652817\n",
      "15802291.22909581\n",
      "15800882.7992321\n",
      "15799486.260806864\n",
      "15798101.513420098\n",
      "15796728.457519539\n",
      "15795366.994393427\n",
      "15794017.026163438\n",
      "15792678.455777619\n",
      "15791351.18700345\n",
      "15790035.124420911\n",
      "15788730.17341559\n",
      "15787436.240171934\n",
      "15786153.231666483\n",
      "15784881.055661159\n",
      "15783619.62069666\n",
      "15782368.836085878\n",
      "15781128.611907395\n",
      "15779898.858998986\n",
      "15778679.48895124\n",
      "15777470.414101172\n",
      "15776271.547525968\n",
      "15775082.803036666\n",
      "15773904.09517207\n",
      "15772735.339192446\n",
      "15771576.45107361\n",
      "15770427.34750073\n",
      "15769287.945862425\n",
      "15768158.164244859\n",
      "15767037.92142569\n",
      "15765927.136868447\n",
      "15764825.730716573\n",
      "15763733.623787766\n",
      "15762650.73756823\n",
      "15761576.994207125\n",
      "15760512.316510856\n",
      "15759456.627937585\n",
      "15758409.85259175\n",
      "15757371.915218564\n",
      "15756342.741198605\n",
      "15755322.256542454\n",
      "15754310.387885453\n",
      "15753307.0624823\n",
      "15752312.208201906\n",
      "15751325.753522193\n",
      "15750347.627524946\n",
      "15749377.759890722\n",
      "15748416.080893768\n",
      "15747462.521397045\n",
      "15746517.012847235\n",
      "15745579.487269819\n",
      "15744649.877264202\n",
      "15743728.115998842\n",
      "15742814.13720644\n",
      "15741907.875179254\n",
      "15741009.264764262\n",
      "15740118.241358545\n",
      "15739234.740904639\n",
      "15738358.699885901\n",
      "15737490.055321988\n",
      "15736628.744764281\n",
      "15735774.706291439\n",
      "15734927.878504906\n",
      "15734088.20052453\n",
      "15733255.611984158\n",
      "15732430.053027328\n",
      "15731611.464302924\n",
      "15730799.786960978\n",
      "15729994.962648349\n",
      "15729196.933504587\n",
      "15728405.642157797\n",
      "15727621.031720432\n",
      "15726843.04578524\n",
      "15726071.62842129\n",
      "15725306.72416979\n",
      "15724548.27804026\n",
      "15723796.235506471\n",
      "15723050.54250255\n",
      "15722311.145419132\n",
      "15721577.991099484\n",
      "15720851.026835639\n",
      "15720130.200364696\n",
      "15719415.459864957\n",
      "15718706.753952308\n",
      "15718004.03167645\n",
      "15717307.242517246\n",
      "15716616.336381128\n",
      "15715931.263597468\n",
      "15715251.974914985\n",
      "15714578.421498243\n",
      "15713910.554924149\n",
      "15713248.327178407\n",
      "15712591.690652156\n",
      "15711940.598138431\n",
      "15711295.002828903\n",
      "15710654.858310437\n",
      "15710020.118561722\n",
      "15709390.737950055\n",
      "15708766.671227997\n",
      "15708147.873530107\n",
      "15707534.300369801\n",
      "15706925.907636046\n",
      "15706322.65159028\n",
      "15705724.488863183\n",
      "15705131.376451649\n",
      "15704543.27171562\n",
      "15703960.13237508\n",
      "15703381.916506944\n",
      "15702808.582542121\n",
      "15702240.089262454\n",
      "15701676.39579784\n",
      "15701117.461623209\n",
      "15700563.246555647\n",
      "15700013.710751534\n",
      "15699468.814703615\n",
      "15698928.519238211\n",
      "15698392.785512405\n",
      "15697861.575011224\n",
      "15697334.849544851\n",
      "15696812.571245933\n",
      "15696294.702566853\n",
      "15695781.206276981\n",
      "15695272.045460014\n",
      "15694767.18351135\n",
      "15694266.584135476\n",
      "15693770.211343275\n",
      "15693278.0294495\n",
      "15692790.003070213\n",
      "15692306.0971202\n",
      "15691826.2768105\n",
      "15691350.50764587\n",
      "15690878.755422277\n",
      "15690410.98622451\n",
      "15689947.16642373\n",
      "15689487.262674954\n",
      "15689031.241914785\n",
      "15688579.071358986\n",
      "15688130.718500094\n",
      "15687686.151105111\n",
      "15687245.337213207\n",
      "15686808.245133365\n",
      "15686374.843442159\n",
      "15685945.10098147\n",
      "15685518.98685625\n",
      "15685096.47043228\n",
      "15684677.521334024\n",
      "15684262.109442357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15683850.204892509\n",
      "15683441.77807181\n",
      "15683036.799617648\n",
      "15682635.24041528\n",
      "15682237.071595836\n",
      "15681842.264534151\n",
      "15681450.79084673\n",
      "15681062.622389743\n",
      "15680677.73125699\n",
      "15680296.089777866\n",
      "15679917.670515401\n",
      "15679542.446264245\n",
      "15679170.390048811\n",
      "15678801.475121181\n",
      "15678435.674959358\n",
      "15678072.963265201\n",
      "15677713.31396266\n",
      "15677356.701195799\n",
      "15677003.099327011\n",
      "15676652.482935147\n",
      "15676304.826813703\n",
      "15675960.105968956\n",
      "15675618.29561824\n",
      "15675279.37118811\n",
      "15674943.308312627\n",
      "15674610.082831528\n",
      "15674279.670788566\n",
      "15673952.048429769\n",
      "15673627.192201694\n",
      "15673305.078749763\n",
      "15672985.68491661\n",
      "15672668.987740347\n",
      "15672354.96445299\n",
      "15672043.592478752\n",
      "15671734.849432496\n",
      "15671428.713118067\n",
      "15671125.161526673\n",
      "15670824.172835404\n",
      "15670525.72540558\n",
      "15670229.797781195\n",
      "15669936.368687434\n",
      "15669645.417029066\n",
      "15669356.921888998\n",
      "15669070.862526745\n",
      "15668787.218376903\n",
      "15668505.969047729\n",
      "15668227.094319662\n",
      "15667950.574143805\n",
      "15667676.388640579\n",
      "15667404.518098217\n",
      "15667134.942971434\n",
      "15666867.6438799\n",
      "15666602.601606961\n",
      "15666339.797098178\n",
      "15666079.211460007\n",
      "15665820.825958436\n",
      "15665564.622017598\n",
      "15665310.581218481\n",
      "15665058.685297573\n",
      "15664808.916145561\n",
      "15664561.25580606\n",
      "15664315.686474247\n",
      "15664072.190495657\n",
      "15663830.750364877\n",
      "15663591.348724278\n",
      "15663353.968362797\n",
      "15663118.592214687\n",
      "15662885.203358267\n",
      "15662653.78501476\n",
      "15662424.320547024\n",
      "15662196.793458397\n",
      "15661971.187391503\n",
      "15661747.48612706\n",
      "15661525.673582736\n",
      "15661305.733811975\n",
      "15661087.65100286\n",
      "15660871.409476994\n",
      "15660656.993688319\n",
      "15660444.388222072\n",
      "15660233.577793596\n",
      "15660024.54724733\n",
      "15659817.281555614\n",
      "15659611.765817719\n",
      "15659407.985258706\n",
      "15659205.925228363\n",
      "15659005.571200196\n",
      "15658806.908770358\n",
      "15658609.923656601\n",
      "15658414.601697272\n",
      "15658220.928850265\n",
      "15658028.891192067\n",
      "15657838.474916685\n",
      "15657649.666334724\n",
      "15657462.451872353\n",
      "15657276.818070343\n",
      "15657092.751583103\n",
      "15656910.239177724\n",
      "15656729.26773302\n",
      "15656549.824238589\n",
      "15656371.895793876\n",
      "15656195.469607258\n",
      "15656020.532995088\n",
      "15655847.073380806\n",
      "15655675.07829408\n",
      "15655504.535369815\n",
      "15655335.43234736\n",
      "15655167.757069526\n",
      "15655001.497481816\n",
      "15654836.6416315\n",
      "15654673.177666748\n",
      "15654511.093835797\n",
      "15654350.37848614\n",
      "15654191.020063588\n",
      "15654033.007111598\n",
      "15653876.328270236\n",
      "15653720.972275576\n",
      "15653566.92795878\n",
      "15653414.184245259\n",
      "15653262.730153985\n",
      "15653112.554796603\n",
      "15652963.6473767\n",
      "15652815.997189019\n",
      "15652669.59361871\n",
      "15652524.42614051\n",
      "15652380.484318051\n",
      "15652237.75780303\n",
      "15652096.236334594\n",
      "15651955.90973845\n",
      "15651816.767926242\n",
      "15651678.800894797\n",
      "15651541.998725377\n",
      "15651406.351582995\n",
      "15651271.849715706\n",
      "15651138.483453892\n",
      "15651006.243209606\n",
      "15650875.119475814\n",
      "15650745.102825759\n",
      "15650616.183912296\n",
      "15650488.353467183\n",
      "15650361.602300422\n",
      "15650235.921299629\n",
      "15650111.301429326\n",
      "15649987.73373035\n",
      "15649865.209319184\n",
      "15649743.719387269\n",
      "15649623.255200481\n",
      "15649503.808098374\n",
      "15649385.369493686\n",
      "15649267.930871598\n",
      "15649151.483789248\n",
      "15649036.019874994\n",
      "15648921.530827884\n",
      "15648808.008417103\n",
      "15648695.44448129\n",
      "15648583.830927989\n",
      "15648473.159733081\n",
      "15648363.422940176\n",
      "15648254.612660106\n",
      "15648146.72107025\n",
      "15648039.740414076\n",
      "15647933.663000526\n",
      "15647828.481203476\n",
      "15647724.187461218\n",
      "15647620.774275836\n",
      "15647518.234212765\n",
      "15647416.559900181\n",
      "15647315.74402853\n",
      "15647215.77934993\n",
      "15647116.658677734\n",
      "15647018.374885948\n",
      "15646920.920908784\n",
      "15646824.289740043\n",
      "15646728.474432725\n",
      "15646633.468098475\n",
      "15646539.26390711\n",
      "15646445.855086077\n",
      "15646353.23492003\n",
      "15646261.396750333\n",
      "15646170.333974564\n",
      "15646080.04004601\n",
      "15645990.50847327\n",
      "15645901.732819732\n",
      "15645813.706703138\n",
      "15645726.423795128\n",
      "15645639.877820741\n",
      "15645554.062558016\n",
      "15645468.971837526\n",
      "15645384.59954192\n",
      "15645300.9396055\n",
      "15645217.9860138\n",
      "15645135.732803103\n",
      "15645054.174060067\n",
      "15644973.303921264\n",
      "15644893.1165728\n",
      "15644813.606249806\n",
      "15644734.767236156\n",
      "15644656.593863955\n",
      "15644579.080513136\n",
      "15644502.22161111\n",
      "15644426.011632355\n",
      "15644350.445097981\n",
      "15644275.516575348\n",
      "15644201.220677694\n",
      "15644127.552063731\n",
      "15644054.505437294\n",
      "15643982.07554689\n",
      "15643910.257185403\n",
      "15643839.04518967\n",
      "15643768.434440106\n",
      "15643698.419860363\n",
      "15643628.996416962\n",
      "15643560.15911888\n",
      "15643491.903017314\n",
      "15643424.223205153\n",
      "15643357.114816783\n",
      "15643290.573027628\n",
      "15643224.593053896\n",
      "15643159.170152105\n",
      "15643094.299618918\n",
      "15643029.976790631\n",
      "15642966.197042964\n",
      "15642902.955790663\n",
      "15642840.248487163\n",
      "15642778.070624322\n",
      "15642716.41773207\n",
      "15642655.285378022\n",
      "15642594.669167273\n",
      "15642534.564741991\n",
      "15642474.967781156\n",
      "15642415.874000212\n",
      "15642357.279150795\n",
      "15642299.179020397\n",
      "15642241.569432091\n",
      "15642184.446244199\n",
      "15642127.805350013\n",
      "15642071.642677536\n",
      "15642015.95418909\n",
      "15641960.735881127\n",
      "15641905.983783882\n",
      "15641851.693961132\n",
      "15641797.86250987\n",
      "15641744.485560033\n",
      "15641691.559274253\n",
      "15641639.079847546\n",
      "15641587.043507067\n",
      "15641535.446511831\n",
      "15641484.285152404\n",
      "15641433.555750677\n",
      "15641383.254659666\n",
      "15641333.378263077\n",
      "15641283.922975205\n",
      "15641234.885240622\n",
      "15641186.261533897\n",
      "15641138.048359374\n",
      "15641090.242250923\n",
      "15641042.83977164\n",
      "15640995.837513695\n",
      "15640949.23209799\n",
      "15640903.020173958\n",
      "15640857.198419327\n",
      "15640811.76353989\n",
      "15640766.712269254\n",
      "15640722.04136857\n",
      "15640677.747626375\n",
      "15640633.827858292\n",
      "15640590.278906822\n",
      "15640547.097641189\n",
      "15640504.280956957\n",
      "15640461.825775975\n",
      "15640419.729046054\n",
      "15640377.987740764\n",
      "15640336.598859245\n",
      "15640295.559425969\n",
      "15640254.866490522\n",
      "15640214.517127415\n",
      "15640174.508435844\n",
      "15640134.837539501\n",
      "15640095.501586385\n",
      "15640056.497748522\n",
      "15640017.823221872\n",
      "15639979.47522605\n",
      "15639941.451004114\n",
      "15639903.747822441\n",
      "15639866.362970484\n",
      "15639829.293760566\n",
      "15639792.537527677\n",
      "15639756.091629382\n",
      "15639719.953445483\n",
      "15639684.12037794\n",
      "15639648.589850647\n",
      "15639613.359309245\n",
      "15639578.426220926\n",
      "15639543.788074277\n",
      "15639509.442379119\n",
      "15639475.38666624\n",
      "15639441.618487325\n",
      "15639408.1354147\n",
      "15639374.935041202\n",
      "15639342.014979998\n",
      "15639309.372864407\n",
      "15639277.006347684\n",
      "15639244.913102973\n",
      "15639213.090822997\n",
      "15639181.537220024\n",
      "15639150.250025565\n",
      "15639119.226990337\n",
      "15639088.465884035\n",
      "15639057.964495169\n",
      "15639027.720630936\n",
      "15638997.73211705\n",
      "15638967.996797582\n",
      "15638938.51253478\n",
      "15638909.277208967\n",
      "15638880.288718384\n",
      "15638851.544978954\n",
      "15638823.043924248\n",
      "15638794.783505255\n",
      "15638766.761690296\n",
      "15638738.976464808\n",
      "15638711.425831262\n",
      "15638684.107808994\n",
      "15638657.020434052\n",
      "15638630.161759071\n",
      "15638603.529853122\n",
      "15638577.122801583\n",
      "15638550.938705998\n",
      "15638524.975683957\n",
      "15638499.231868904\n",
      "15638473.705410069\n",
      "15638448.394472305\n",
      "15638423.297235966\n",
      "15638398.411896754\n",
      "15638373.736665597\n",
      "15638349.269768571\n",
      "15638325.00944668\n",
      "15638300.953955805\n",
      "15638277.101566566\n",
      "15638253.450564139\n",
      "15638229.999248218\n",
      "15638206.745932853\n",
      "15638183.688946307\n",
      "15638160.826630957\n",
      "15638138.157343183\n",
      "15638115.679453274\n",
      "15638093.391345207\n",
      "15638071.291416675\n",
      "15638049.378078874\n",
      "15638027.649756389\n",
      "15638006.104887126\n",
      "15637984.741922194\n",
      "15637963.559325771\n",
      "15637942.555574983\n",
      "15637921.729159825\n",
      "15637901.078583065\n",
      "15637880.602360079\n",
      "15637860.299018783\n",
      "15637840.167099547\n",
      "15637820.205155032\n",
      "15637800.41175014\n",
      "15637780.78546188\n",
      "15637761.324879266\n",
      "15637742.028603263\n",
      "15637722.895246603\n",
      "15637703.923433768\n",
      "15637685.111800816\n",
      "15637666.458995355\n",
      "15637647.963676397\n",
      "15637629.624514263\n",
      "15637611.44019053\n",
      "15637593.40939787\n",
      "15637575.530840058\n",
      "15637557.8032317\n",
      "15637540.22529837\n",
      "15637522.795776356\n",
      "15637505.513412593\n",
      "15637488.37696462\n",
      "15637471.385200484\n",
      "15637454.536898589\n",
      "15637437.830847677\n",
      "15637421.265846742\n",
      "15637404.840704868\n",
      "15637388.554241227\n",
      "15637372.405284952\n",
      "15637356.392675059\n",
      "15637340.515260378\n",
      "15637324.771899436\n",
      "15637309.161460426\n",
      "15637293.682821069\n",
      "15637278.334868576\n",
      "15637263.11649957\n",
      "15637248.026619935\n",
      "15637233.064144868\n",
      "15637218.22799866\n",
      "15637203.517114727\n",
      "15637188.930435466\n",
      "15637174.466912214\n",
      "15637160.125505153\n",
      "15637145.905183258\n",
      "15637131.804924194\n",
      "15637117.823714266\n",
      "15637103.960548347\n",
      "15637090.214429779\n",
      "15637076.584370336\n",
      "15637063.069390094\n",
      "15637049.668517461\n",
      "15637036.380789015\n",
      "15637023.20524949\n",
      "15637010.140951635\n",
      "15636997.186956262\n",
      "15636984.342332061\n",
      "15636971.606155628\n",
      "15636958.977511307\n",
      "15636946.455491226\n",
      "15636934.039195132\n",
      "15636921.727730406\n",
      "15636909.520211942\n",
      "15636897.415762126\n",
      "15636885.413510729\n",
      "15636873.512594914\n",
      "15636861.712159066\n",
      "15636850.011354841\n",
      "15636838.409341058\n",
      "15636826.905283604\n",
      "15636815.49835545\n",
      "15636804.187736511\n",
      "15636792.972613644\n",
      "15636781.852180589\n",
      "15636770.82563786\n",
      "15636759.89219275\n",
      "15636749.051059207\n",
      "15636738.301457861\n",
      "15636727.642615894\n",
      "15636717.073767025\n",
      "15636706.594151437\n",
      "15636696.203015732\n",
      "15636685.899612857\n",
      "15636675.6832021\n",
      "15636665.553048965\n",
      "15636655.508425184\n",
      "15636645.548608614\n",
      "15636635.672883246\n",
      "15636625.880539082\n",
      "15636616.170872135\n",
      "15636606.543184357\n",
      "15636596.996783584\n",
      "15636587.530983511\n",
      "15636578.145103635\n",
      "15636568.838469176\n",
      "15636559.610411055\n",
      "15636550.460265866\n",
      "15636541.387375768\n",
      "15636532.39108851\n",
      "15636523.470757315\n",
      "15636514.62574088\n",
      "15636505.855403336\n",
      "15636497.15911416\n",
      "15636488.536248146\n",
      "15636479.9861854\n",
      "15636471.508311225\n",
      "15636463.102016138\n",
      "15636454.766695784\n",
      "15636446.501750922\n",
      "15636438.306587372\n",
      "15636430.180615967\n",
      "15636422.123252518\n",
      "15636414.13391776\n",
      "15636406.212037321\n",
      "15636398.357041692\n",
      "15636390.56836614\n",
      "15636382.845450751\n",
      "15636375.18774029\n",
      "15636367.594684236\n",
      "15636360.065736694\n",
      "15636352.600356404\n",
      "15636345.19800668\n",
      "15636337.85815533\n",
      "15636330.580274675\n",
      "15636323.363841513\n",
      "15636316.208337033\n",
      "15636309.113246802\n",
      "15636302.078060744\n",
      "15636295.10227309\n",
      "15636288.185382338\n",
      "15636281.3268912\n",
      "15636274.526306631\n",
      "15636267.78313971\n",
      "15636261.096905662\n",
      "15636254.467123803\n",
      "15636247.893317478\n",
      "15636241.375014115\n",
      "15636234.911745103\n",
      "15636228.503045756\n",
      "15636222.148455339\n",
      "15636215.847517041\n",
      "15636209.599777851\n",
      "15636203.40478862\n",
      "15636197.262103967\n",
      "15636191.171282286\n",
      "15636185.131885674\n",
      "15636179.14347999\n",
      "15636173.205634682\n",
      "15636167.317922886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15636161.479921304\n",
      "15636155.691210235\n",
      "15636149.951373523\n",
      "15636144.259998534\n",
      "15636138.616676066\n",
      "15636133.021000436\n",
      "15636127.472569356\n",
      "15636121.970983943\n",
      "15636116.51584866\n",
      "15636111.106771344\n",
      "15636105.743363112\n",
      "15636100.425238397\n",
      "15636095.152014833\n",
      "15636089.923313359\n",
      "15636084.738758046\n",
      "15636079.597976161\n",
      "15636074.500598151\n",
      "15636069.446257534\n",
      "15636064.434590954\n",
      "15636059.465238094\n",
      "15636054.537841715\n",
      "15636049.652047578\n",
      "15636044.807504417\n",
      "15636040.003863968\n",
      "15636035.240780871\n",
      "15636030.517912704\n",
      "15636025.83491993\n",
      "15636021.19146588\n",
      "15636016.587216742\n",
      "15636012.021841489\n",
      "15636007.495011905\n",
      "15636003.006402543\n",
      "15635998.555690723\n",
      "15635994.142556472\n",
      "15635989.766682522\n",
      "15635985.427754264\n",
      "15635981.12545978\n",
      "15635976.859489786\n",
      "15635972.629537558\n",
      "15635968.435299015\n",
      "15635964.276472619\n",
      "15635960.152759396\n",
      "15635956.063862864\n",
      "15635952.009489078\n",
      "15635947.989346556\n"
     ]
    }
   ],
   "source": [
    "observations = 30\n",
    "\n",
    "# Train the model\n",
    "for i in range (1000):\n",
    "    outputs = inputs *  weights + biases\n",
    "    deltas = outputs - targets\n",
    "    \n",
    "    # Follow the L2-norm loss formula divided by 2\n",
    "    # Division by a constant doesn't change the logic of the loss, as it is still lower for higher\n",
    "    # accuracy\n",
    "    loss = np.sum(deltas ** 2) / 2 / observations\n",
    "    \n",
    "    # Want to see the loss decrease after each iteration\n",
    "    print(loss)\n",
    "    \n",
    "    # Update the weights and the biases following the gradient descent logic\n",
    "    deltas_scaled = deltas / observations\n",
    "    weights = weights - learning_rate *np.dot(inputs.T, deltas_scaled)\n",
    "    biases = biases - learning_rate * np.sum(deltas_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9459.72830713] [25726.38981324]\n"
     ]
    }
   ],
   "source": [
    "# Print the weights and the biases\n",
    "print(weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot last outputs vs targets\n",
    "plt.plot(outputs, targets)\n",
    "plt.xlabel('outputs')\n",
    "plt.ylabel('targets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 49\n",
    "Preprocessing refers to any manipulation of the dataset before running it through the model. This section will focus on data transformation. \n",
    "\n",
    "Motivation:\n",
    "- Compatablility with the libraries you are using\n",
    "- Orders of magnitude, bigger values will affect the model more\n",
    "- Generalization: using the same model for different issues\n",
    "\n",
    "Often we are not interested in an absolute value, but a relative value. For instance if you go to Apple stock price, you will see numbers in red and green which are relative metrics, as they are relative change of the stock price. The most common problem when working with numerical data is the difference in magnitudes of the data. We can fix this by using standardization, or feature scaling. Standardization is the process of transoforming data into a standard scale. A very common way to approach this process is to subtract the mean and divide by the standard deviation. Feature scaling allows our linear combinations treats all variables equally. Plus, we can make much more sense of the data. PCA is another preprocessing method which is a dimension reduction technique. Whitening is another technique that is performed after PCA which removes underlying correlations between datapoints. We cannot get to PCA and Whitening in this video.\n",
    "\n",
    "When dealing with categorical data, you must be able to convert your categorical data into numbers. Imagine your shop has three products bread, yogurt, and muffins. You can just enumerate like (1, 2, 3), but this implies that there is some order to them. This is typically an issue. So instead, you must either use one hot encoding or binary encoding. \n",
    "\n",
    "Binary Encoding starts with bread -1 , yogurt - 2, and muffin - 3. Convert these numbers into binary: bread - 01, yogurt - 10, muffin - 11, Now, you can create a table of two variables where variable one contains the first number, so for instance in bread, '0', and then the second  variable  contains the second number so for instanc in bread , 1. However, if you did it this way, it would imply yogurt and bread are opposites and that's not necessarily true, so even binary encoding can prove to be troublesome.\n",
    "\n",
    "In one hot encoding, you create a variable for each type of category such as a variable for bread, yogurt, and muffin each. Then, bread would be encoded as bread = 1, yogurt - 0, and muffin = 0. However, one hot encoding has one big problem, if you have 12,000 categories you wouldn't want to make 12,000 variables. Therefore you can just "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For my own practice, I'll be using clickstream data from an online store \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('~/Desktop/e-shop data and description/e-shop clothing 2008.csv', delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>order</th>\n",
       "      <th>country</th>\n",
       "      <th>session ID</th>\n",
       "      <th>page 1 (main category)</th>\n",
       "      <th>page 2 (clothing model)</th>\n",
       "      <th>colour</th>\n",
       "      <th>location</th>\n",
       "      <th>model photography</th>\n",
       "      <th>price</th>\n",
       "      <th>price 2</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A13</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A16</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>B4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>B17</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>B8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  order  country  session ID  page 1 (main category)  \\\n",
       "0  2008      4    1      1       29           1                       1   \n",
       "1  2008      4    1      2       29           1                       1   \n",
       "2  2008      4    1      3       29           1                       2   \n",
       "3  2008      4    1      4       29           1                       2   \n",
       "4  2008      4    1      5       29           1                       2   \n",
       "\n",
       "  page 2 (clothing model)  colour  location  model photography  price  \\\n",
       "0                     A13       1         5                  1     28   \n",
       "1                     A16       1         6                  1     33   \n",
       "2                      B4      10         2                  1     52   \n",
       "3                     B17       6         6                  2     38   \n",
       "4                      B8       4         3                  2     52   \n",
       "\n",
       "   price 2  page  \n",
       "0        2     1  \n",
       "1        2     1  \n",
       "2        1     1  \n",
       "3        2     1  \n",
       "4        1     1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>order</th>\n",
       "      <th>country</th>\n",
       "      <th>session ID</th>\n",
       "      <th>page 1 (main category)</th>\n",
       "      <th>colour</th>\n",
       "      <th>location</th>\n",
       "      <th>model photography</th>\n",
       "      <th>...</th>\n",
       "      <th>page 2 (clothing model)_P75</th>\n",
       "      <th>page 2 (clothing model)_P76</th>\n",
       "      <th>page 2 (clothing model)_P77</th>\n",
       "      <th>page 2 (clothing model)_P78</th>\n",
       "      <th>page 2 (clothing model)_P79</th>\n",
       "      <th>page 2 (clothing model)_P8</th>\n",
       "      <th>page 2 (clothing model)_P80</th>\n",
       "      <th>page 2 (clothing model)_P81</th>\n",
       "      <th>page 2 (clothing model)_P82</th>\n",
       "      <th>page 2 (clothing model)_P9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  order  country  session ID  page 1 (main category)  \\\n",
       "0  2008      4    1      1       29           1                       1   \n",
       "1  2008      4    1      2       29           1                       1   \n",
       "2  2008      4    1      3       29           1                       2   \n",
       "3  2008      4    1      4       29           1                       2   \n",
       "4  2008      4    1      5       29           1                       2   \n",
       "\n",
       "   colour  location  model photography  ...  page 2 (clothing model)_P75  \\\n",
       "0       1         5                  1  ...                            0   \n",
       "1       1         6                  1  ...                            0   \n",
       "2      10         2                  1  ...                            0   \n",
       "3       6         6                  2  ...                            0   \n",
       "4       4         3                  2  ...                            0   \n",
       "\n",
       "   page 2 (clothing model)_P76  page 2 (clothing model)_P77  \\\n",
       "0                            0                            0   \n",
       "1                            0                            0   \n",
       "2                            0                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "\n",
       "   page 2 (clothing model)_P78  page 2 (clothing model)_P79  \\\n",
       "0                            0                            0   \n",
       "1                            0                            0   \n",
       "2                            0                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "\n",
       "   page 2 (clothing model)_P8  page 2 (clothing model)_P80  \\\n",
       "0                           0                            0   \n",
       "1                           0                            0   \n",
       "2                           0                            0   \n",
       "3                           0                            0   \n",
       "4                           0                            0   \n",
       "\n",
       "   page 2 (clothing model)_P81  page 2 (clothing model)_P82  \\\n",
       "0                            0                            0   \n",
       "1                            0                            0   \n",
       "2                            0                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "\n",
       "   page 2 (clothing model)_P9  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "\n",
       "[5 rows x 230 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding - to convert categorical data to continuous\n",
    "df['page 2 (clothing model)'] = df['page 2 (clothing model)'].astype(str)\n",
    "df = pd.get_dummies(df)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        -1.259355\n",
       "1        -0.860888\n",
       "2         0.653286\n",
       "3        -0.462421\n",
       "4         0.653286\n",
       "            ...   \n",
       "165469    1.848687\n",
       "165470    1.450220\n",
       "165471   -0.063954\n",
       "165472   -0.063954\n",
       "165473    1.051753\n",
       "Name: price, Length: 165474, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing the price \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "continuous_variables = ['price', 'price 2']\n",
    "scaler = StandardScaler()\n",
    "df[continuous_variables]=scaler.fit_transform(df[continuous_variables])\n",
    "df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1.023952\n",
       "1         1.023952\n",
       "2        -0.976608\n",
       "3         1.023952\n",
       "4        -0.976608\n",
       "            ...   \n",
       "165469   -0.976608\n",
       "165470   -0.976608\n",
       "165471    1.023952\n",
       "165472   -0.976608\n",
       "165473   -0.976608\n",
       "Name: price 2, Length: 165474, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 50 \n",
    "Classifying on the MNIST\n",
    "Each image in dataset is 28 by 28 pixels, so we can think about the problem as a 28 x 28 matrix where input values are from 0 to 255. A 28x28 photo has 784 pixels, we want to convert each 28 x 28 matrix to a 784 x 1. Each pixel is an input in the input layer. We will prepare out data and preprocess it. Create training, validation and test datasets. Outline the model and choose the activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /Users/jarellano/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
      "local data directory. If you'd instead prefer to read directly from our public\n",
      "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
      "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e34145fd43465596778de59cc5e4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mDataset mnist downloaded and prepared to /Users/jarellano/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Import the dataset\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing dataset\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our number of validation samples is 10% of our training data\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are scaling our data \n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will shuffle our data for preprocessing\n",
    "BUFFER_SIZE = 10000\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "validation_inputs, validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outline the model\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 50\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation='softmax')   \n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the optimizer and the loss function\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 3s - loss: 0.4112 - accuracy: 0.8820 - val_loss: 0.2125 - val_accuracy: 0.9375\n",
      "Epoch 2/5\n",
      "540/540 - 1s - loss: 0.1804 - accuracy: 0.9474 - val_loss: 0.1608 - val_accuracy: 0.9525\n",
      "Epoch 3/5\n",
      "540/540 - 1s - loss: 0.1358 - accuracy: 0.9608 - val_loss: 0.1351 - val_accuracy: 0.9587\n",
      "Epoch 4/5\n",
      "540/540 - 1s - loss: 0.1117 - accuracy: 0.9667 - val_loss: 0.1112 - val_accuracy: 0.9643\n",
      "Epoch 5/5\n",
      "540/540 - 1s - loss: 0.0939 - accuracy: 0.9729 - val_loss: 0.0988 - val_accuracy: 0.9705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f98562288e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "model.fit(train_data, epochs = NUM_EPOCHS, validation_data=(validation_inputs, validation_targets), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 801us/step - loss: 0.1059 - accuracy: 0.9697\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.11. Test accuracy: 96.97%\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this next example I followed along the https://www.tensorflow.org/hub/tutorials/tf2_text_classification\n",
    "# with imdb data. The steps flow about the same, but uses tensorflow_hub library for transfer\n",
    "# learning. \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Import the dataset and split between training and testing data\n",
    "train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], \n",
    "                                  batch_size=-1, as_supervised=True)\n",
    "\n",
    "train_examples, train_labels = tfds.as_numpy(train_data)\n",
    "test_examples, test_labels = tfds.as_numpy(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our validation set\n",
    "x_val = train_examples[:10000]\n",
    "partial_x_train = train_examples[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7f984e521ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7f984e521ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7f984e53ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7f984e53ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 20), dtype=float32, numpy=\n",
       "array([[ 1.765786  , -3.882232  ,  3.9134233 , -1.5557289 , -3.3362343 ,\n",
       "        -1.7357955 , -1.9954445 ,  1.2989551 ,  5.081598  , -1.1041286 ,\n",
       "        -2.0503852 , -0.72675157, -0.65675956,  0.24436149, -3.7208383 ,\n",
       "         2.0954835 ,  2.2969332 , -2.0689783 , -2.9489717 , -1.1315987 ],\n",
       "       [ 1.8804485 , -2.5852382 ,  3.4066997 ,  1.0982676 , -4.056685  ,\n",
       "        -4.891284  , -2.785554  ,  1.3874227 ,  3.8476458 , -0.9256538 ,\n",
       "        -1.896706  ,  1.2113281 ,  0.11474707,  0.76209456, -4.8791065 ,\n",
       "         2.906149  ,  4.7087674 , -2.3652055 , -3.5015898 , -1.6390051 ],\n",
       "       [ 0.71152234, -0.6353217 ,  1.7385626 , -1.1168286 , -0.5451594 ,\n",
       "        -1.1808156 ,  0.09504455,  1.4653089 ,  0.66059524,  0.79308075,\n",
       "        -2.2268345 ,  0.07446612, -1.4075904 , -0.70645386, -1.907037  ,\n",
       "         1.4419787 ,  1.9551861 , -0.42660055, -2.8022065 ,  0.43727064]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(model, output_shape=[20], input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "hub_layer(train_examples[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_1 (KerasLayer)   (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 400,373\n",
      "Trainable params: 400,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building out the full model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "30/30 [==============================] - 1s 50ms/step - loss: 0.6917 - accuracy: 0.5688 - val_loss: 0.6418 - val_accuracy: 0.6355\n",
      "Epoch 2/40\n",
      "30/30 [==============================] - 1s 46ms/step - loss: 0.6110 - accuracy: 0.6687 - val_loss: 0.5970 - val_accuracy: 0.6845\n",
      "Epoch 3/40\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.5653 - accuracy: 0.7100 - val_loss: 0.5591 - val_accuracy: 0.7187\n",
      "Epoch 4/40\n",
      "30/30 [==============================] - 1s 47ms/step - loss: 0.5257 - accuracy: 0.7473 - val_loss: 0.5242 - val_accuracy: 0.7472\n",
      "Epoch 5/40\n",
      "30/30 [==============================] - 2s 50ms/step - loss: 0.4855 - accuracy: 0.7781 - val_loss: 0.4921 - val_accuracy: 0.7693\n",
      "Epoch 6/40\n",
      "30/30 [==============================] - 2s 50ms/step - loss: 0.4485 - accuracy: 0.8025 - val_loss: 0.4618 - val_accuracy: 0.7898\n",
      "Epoch 7/40\n",
      "30/30 [==============================] - 1s 46ms/step - loss: 0.4136 - accuracy: 0.8220 - val_loss: 0.4343 - val_accuracy: 0.8070\n",
      "Epoch 8/40\n",
      "30/30 [==============================] - 1s 46ms/step - loss: 0.3811 - accuracy: 0.8425 - val_loss: 0.4104 - val_accuracy: 0.8200\n",
      "Epoch 9/40\n",
      "30/30 [==============================] - 2s 51ms/step - loss: 0.3516 - accuracy: 0.8572 - val_loss: 0.3903 - val_accuracy: 0.8305\n",
      "Epoch 10/40\n",
      "30/30 [==============================] - 1s 47ms/step - loss: 0.3245 - accuracy: 0.8708 - val_loss: 0.3717 - val_accuracy: 0.8385\n",
      "Epoch 11/40\n",
      "30/30 [==============================] - 1s 48ms/step - loss: 0.3012 - accuracy: 0.8812 - val_loss: 0.3568 - val_accuracy: 0.8460\n",
      "Epoch 12/40\n",
      "30/30 [==============================] - 1s 46ms/step - loss: 0.2789 - accuracy: 0.8931 - val_loss: 0.3451 - val_accuracy: 0.8516\n",
      "Epoch 13/40\n",
      "30/30 [==============================] - 1s 44ms/step - loss: 0.2589 - accuracy: 0.9011 - val_loss: 0.3349 - val_accuracy: 0.8565\n",
      "Epoch 14/40\n",
      "30/30 [==============================] - 1s 44ms/step - loss: 0.2414 - accuracy: 0.9107 - val_loss: 0.3268 - val_accuracy: 0.8623\n",
      "Epoch 15/40\n",
      "30/30 [==============================] - 1s 45ms/step - loss: 0.2253 - accuracy: 0.9192 - val_loss: 0.3224 - val_accuracy: 0.8635\n",
      "Epoch 16/40\n",
      "30/30 [==============================] - 1s 43ms/step - loss: 0.2100 - accuracy: 0.9252 - val_loss: 0.3219 - val_accuracy: 0.8650\n",
      "Epoch 17/40\n",
      "30/30 [==============================] - 1s 47ms/step - loss: 0.1964 - accuracy: 0.9303 - val_loss: 0.3125 - val_accuracy: 0.8699\n",
      "Epoch 18/40\n",
      "30/30 [==============================] - 1s 48ms/step - loss: 0.1824 - accuracy: 0.9376 - val_loss: 0.3101 - val_accuracy: 0.8722\n",
      "Epoch 19/40\n",
      "30/30 [==============================] - 1s 49ms/step - loss: 0.1704 - accuracy: 0.9433 - val_loss: 0.3101 - val_accuracy: 0.8727\n",
      "Epoch 20/40\n",
      "30/30 [==============================] - 1s 46ms/step - loss: 0.1592 - accuracy: 0.9485 - val_loss: 0.3086 - val_accuracy: 0.8739\n",
      "Epoch 21/40\n",
      "30/30 [==============================] - 1s 46ms/step - loss: 0.1485 - accuracy: 0.9525 - val_loss: 0.3109 - val_accuracy: 0.8743\n",
      "Epoch 22/40\n",
      "30/30 [==============================] - 1s 48ms/step - loss: 0.1389 - accuracy: 0.9563 - val_loss: 0.3116 - val_accuracy: 0.8755\n",
      "Epoch 23/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.1297 - accuracy: 0.9590 - val_loss: 0.3131 - val_accuracy: 0.8757\n",
      "Epoch 24/40\n",
      "30/30 [==============================] - 1s 50ms/step - loss: 0.1213 - accuracy: 0.9644 - val_loss: 0.3191 - val_accuracy: 0.8751\n",
      "Epoch 25/40\n",
      "30/30 [==============================] - 1s 49ms/step - loss: 0.1140 - accuracy: 0.9661 - val_loss: 0.3212 - val_accuracy: 0.8750\n",
      "Epoch 26/40\n",
      "30/30 [==============================] - 1s 49ms/step - loss: 0.1053 - accuracy: 0.9702 - val_loss: 0.3242 - val_accuracy: 0.8754\n",
      "Epoch 27/40\n",
      "30/30 [==============================] - 1s 46ms/step - loss: 0.0986 - accuracy: 0.9727 - val_loss: 0.3285 - val_accuracy: 0.8737\n",
      "Epoch 28/40\n",
      "30/30 [==============================] - 1s 47ms/step - loss: 0.0916 - accuracy: 0.9751 - val_loss: 0.3323 - val_accuracy: 0.8754\n",
      "Epoch 29/40\n",
      "30/30 [==============================] - 1s 48ms/step - loss: 0.0858 - accuracy: 0.9782 - val_loss: 0.3418 - val_accuracy: 0.8734\n",
      "Epoch 30/40\n",
      "30/30 [==============================] - 1s 45ms/step - loss: 0.0804 - accuracy: 0.9804 - val_loss: 0.3433 - val_accuracy: 0.8740\n",
      "Epoch 31/40\n",
      "30/30 [==============================] - 1s 45ms/step - loss: 0.0740 - accuracy: 0.9821 - val_loss: 0.3491 - val_accuracy: 0.8731\n",
      "Epoch 32/40\n",
      "30/30 [==============================] - 1s 48ms/step - loss: 0.0695 - accuracy: 0.9837 - val_loss: 0.3552 - val_accuracy: 0.8730\n",
      "Epoch 33/40\n",
      "30/30 [==============================] - 1s 48ms/step - loss: 0.0644 - accuracy: 0.9862 - val_loss: 0.3640 - val_accuracy: 0.8714\n",
      "Epoch 34/40\n",
      "30/30 [==============================] - 1s 47ms/step - loss: 0.0593 - accuracy: 0.9878 - val_loss: 0.3698 - val_accuracy: 0.8718\n",
      "Epoch 35/40\n",
      "30/30 [==============================] - 1s 48ms/step - loss: 0.0552 - accuracy: 0.9893 - val_loss: 0.3762 - val_accuracy: 0.8716\n",
      "Epoch 36/40\n",
      "30/30 [==============================] - 1s 44ms/step - loss: 0.0512 - accuracy: 0.9905 - val_loss: 0.3855 - val_accuracy: 0.8710\n",
      "Epoch 37/40\n",
      "30/30 [==============================] - 1s 46ms/step - loss: 0.0474 - accuracy: 0.9919 - val_loss: 0.3921 - val_accuracy: 0.8704\n",
      "Epoch 38/40\n",
      "30/30 [==============================] - 1s 46ms/step - loss: 0.0440 - accuracy: 0.9934 - val_loss: 0.3998 - val_accuracy: 0.8703\n",
      "Epoch 39/40\n",
      "30/30 [==============================] - 1s 46ms/step - loss: 0.0409 - accuracy: 0.9941 - val_loss: 0.4070 - val_accuracy: 0.8698\n",
      "Epoch 40/40\n",
      "30/30 [==============================] - 1s 46ms/step - loss: 0.0378 - accuracy: 0.9951 - val_loss: 0.4153 - val_accuracy: 0.8691\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 3ms/step - loss: 0.4467 - accuracy: 0.8550\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_loss, test_accuracy = model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.45. Test accuracy: 85.50%\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 51\n",
    "Create a machine learning that predicts if a customer will buy again. Our model will take in several metrics and show us which are the most important metrics to see if a customer will come back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we must import the libraries once again since we haven't imported them in this file\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "# Each row represents a person in this audiobook data\n",
    "raw_csv_data = np.loadtxt('/Users/jarellano/Desktop/Audiobooks_data.csv', delimiter = ',')\n",
    "unscaled_inputs_all = raw_csv_data[:, 1:-1]\n",
    "targets_all = raw_csv_data[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Case Action plan:\n",
    "- Preprocess the data\n",
    "    - Balance the dataset\n",
    "    - Divide the dataset into three parts, training, validation, and test\n",
    "    - Save the data in a tensor friendly format\n",
    "- Create the machine learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the dataset - we want as many 1s as 0s\n",
    "num_one_targets = int(np.sum(targets_all))\n",
    "zero_targets_counter = 0\n",
    "indices_to_remove = []\n",
    "\n",
    "# Collects the indices of zeros to remove\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i] == 0:\n",
    "        zero_targets_counter += 1\n",
    "        if zero_targets_counter > num_one_targets:\n",
    "            indices_to_remove.append(i)\n",
    "            \n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis = 0)\n",
    "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the inputs\n",
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "train_samples_count = int(0.8 * samples_count)\n",
    "validation_samples_count = int(0.1 * samples_count)\n",
    "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
    "\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
    "validation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count + validation_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count + validation_samples_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the datasets as npz\n",
    "np.savez('/Users/jarellano/Desktop/Audiobooks_data_train', inputs = train_inputs, targets = train_targets)\n",
    "np.savez('/Users/jarellano/Desktop/Audiobooks_data_validation', inputs = validation_inputs, targets = validation_targets)\n",
    "np.savez('/Users/jarellano/Desktop/Audiobooks_data_test', inputs = test_inputs, targets = test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Loads our training data\n",
    "npz = np.load('/Users/jarellano/Desktop/Audiobooks_data_train.npz')\n",
    "\n",
    "# Splits our inputs and targets\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "train_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "# Loads our validation data and splits our inputs and targets\n",
    "npz = np.load('/Users/jarellano/Desktop/Audiobooks_data_validation.npz')\n",
    "validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "# Loads our test data and splits our inputs and targets\n",
    "npz = np.load('/Users/jarellano/Desktop/Audiobooks_data_test.npz')\n",
    "test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 - 0s - loss: 0.6848 - accuracy: 0.5938 - val_loss: 0.6438 - val_accuracy: 0.6398\n",
      "Epoch 2/100\n",
      "5/5 - 0s - loss: 0.6256 - accuracy: 0.6987 - val_loss: 0.6013 - val_accuracy: 0.7002\n",
      "Epoch 3/100\n",
      "5/5 - 0s - loss: 0.5840 - accuracy: 0.7344 - val_loss: 0.5701 - val_accuracy: 0.7315\n",
      "Epoch 4/100\n",
      "5/5 - 0s - loss: 0.5529 - accuracy: 0.7545 - val_loss: 0.5454 - val_accuracy: 0.7204\n",
      "Epoch 5/100\n",
      "5/5 - 0s - loss: 0.5281 - accuracy: 0.7812 - val_loss: 0.5274 - val_accuracy: 0.7338\n",
      "Epoch 6/100\n",
      "5/5 - 0s - loss: 0.5083 - accuracy: 0.7857 - val_loss: 0.5111 - val_accuracy: 0.7383\n",
      "Epoch 7/100\n",
      "5/5 - 0s - loss: 0.4915 - accuracy: 0.7790 - val_loss: 0.4969 - val_accuracy: 0.7472\n",
      "Epoch 8/100\n",
      "5/5 - 0s - loss: 0.4766 - accuracy: 0.7835 - val_loss: 0.4856 - val_accuracy: 0.7517\n",
      "Epoch 9/100\n",
      "5/5 - 0s - loss: 0.4645 - accuracy: 0.7857 - val_loss: 0.4745 - val_accuracy: 0.7562\n",
      "Epoch 10/100\n",
      "5/5 - 0s - loss: 0.4535 - accuracy: 0.7902 - val_loss: 0.4644 - val_accuracy: 0.7606\n",
      "Epoch 11/100\n",
      "5/5 - 0s - loss: 0.4429 - accuracy: 0.7946 - val_loss: 0.4571 - val_accuracy: 0.7584\n",
      "Epoch 12/100\n",
      "5/5 - 0s - loss: 0.4341 - accuracy: 0.7902 - val_loss: 0.4503 - val_accuracy: 0.7539\n",
      "Epoch 13/100\n",
      "5/5 - 0s - loss: 0.4259 - accuracy: 0.7924 - val_loss: 0.4428 - val_accuracy: 0.7606\n",
      "Epoch 14/100\n",
      "5/5 - 0s - loss: 0.4183 - accuracy: 0.8036 - val_loss: 0.4361 - val_accuracy: 0.7673\n",
      "Epoch 15/100\n",
      "5/5 - 0s - loss: 0.4122 - accuracy: 0.8013 - val_loss: 0.4311 - val_accuracy: 0.7696\n",
      "Epoch 16/100\n",
      "5/5 - 0s - loss: 0.4061 - accuracy: 0.8013 - val_loss: 0.4283 - val_accuracy: 0.7673\n",
      "Epoch 17/100\n",
      "5/5 - 0s - loss: 0.4011 - accuracy: 0.8013 - val_loss: 0.4274 - val_accuracy: 0.7651\n",
      "Epoch 18/100\n",
      "5/5 - 0s - loss: 0.3977 - accuracy: 0.8058 - val_loss: 0.4249 - val_accuracy: 0.7651\n",
      "Epoch 19/100\n",
      "5/5 - 0s - loss: 0.3911 - accuracy: 0.8080 - val_loss: 0.4195 - val_accuracy: 0.7696\n",
      "Epoch 20/100\n",
      "5/5 - 0s - loss: 0.3870 - accuracy: 0.8080 - val_loss: 0.4159 - val_accuracy: 0.7696\n",
      "Epoch 21/100\n",
      "5/5 - 0s - loss: 0.3834 - accuracy: 0.8080 - val_loss: 0.4142 - val_accuracy: 0.7696\n",
      "Epoch 22/100\n",
      "5/5 - 0s - loss: 0.3797 - accuracy: 0.8103 - val_loss: 0.4144 - val_accuracy: 0.7696\n",
      "Epoch 23/100\n",
      "5/5 - 0s - loss: 0.3769 - accuracy: 0.8103 - val_loss: 0.4133 - val_accuracy: 0.7696\n",
      "Epoch 24/100\n",
      "5/5 - 0s - loss: 0.3739 - accuracy: 0.8080 - val_loss: 0.4136 - val_accuracy: 0.7696\n",
      "Epoch 25/100\n",
      "5/5 - 0s - loss: 0.3706 - accuracy: 0.8080 - val_loss: 0.4114 - val_accuracy: 0.7696\n",
      "Epoch 26/100\n",
      "5/5 - 0s - loss: 0.3678 - accuracy: 0.8125 - val_loss: 0.4060 - val_accuracy: 0.7740\n",
      "Epoch 27/100\n",
      "5/5 - 0s - loss: 0.3663 - accuracy: 0.8147 - val_loss: 0.4059 - val_accuracy: 0.7763\n",
      "Epoch 28/100\n",
      "5/5 - 0s - loss: 0.3622 - accuracy: 0.8147 - val_loss: 0.4064 - val_accuracy: 0.7763\n",
      "Epoch 29/100\n",
      "5/5 - 0s - loss: 0.3603 - accuracy: 0.8125 - val_loss: 0.4077 - val_accuracy: 0.7718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9852bd3d00>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model - outlines, optimizers, loss, early stopping and training\n",
    "\n",
    "# Setting the input and output sizes\n",
    "input_size = 10\n",
    "output_size = 2\n",
    "\n",
    "# Setting the size of our hidden later\n",
    "hidden_layer_size = 50\n",
    "\n",
    "# defining how our model will look like\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), \n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), \n",
    "    tf.keras.layers.Dense(output_size, activation='softmax') \n",
    "])\n",
    "\n",
    "\n",
    "# Choosing the optimizer and loss function\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setting batch size and the maximum number of epochs\n",
    "batch_size = 100\n",
    "max_epochs = 100\n",
    "\n",
    "# An early stopping mechanism to not allow overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "# fit the model\n",
    "model.fit(train_inputs, \n",
    "          train_targets,  \n",
    "          batch_size=batch_size, \n",
    "          epochs=max_epochs, \n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(validation_inputs, validation_targets),\n",
    "          verbose = 2\n",
    "          )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 745us/step - loss: 0.3591 - accuracy: 0.8103\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.36. Test accuracy: 81.03%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For my own implementation, I decided to use Heart disease data from Cleveland\n",
    "# https://www.kaggle.com/ronitf/heart-disease-uci\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row represents a person and the columns are age, sex, chest pain type,(0 - 3),\n",
    "# resting blood pressure, cholesterol, fasting blood sugar, resting electrocardiographic \n",
    "# results, maximum heart rate, exercise induced angina, ST depression induced by exercise,\n",
    "# slope of the peak exercise, number of major vessels colored by flourosopy, and displays of\n",
    "# thalassemia. The target column is the diagnosis of heart disease (0 or 1)\n",
    "\n",
    "\n",
    "raw_csv_data = np.loadtxt('/Users/jarellano/Desktop/heart.csv', delimiter = ',', skiprows=1)\n",
    "unscaled_inputs_all = raw_csv_data[:, 1:-1]\n",
    "targets_all = raw_csv_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the dataset - we want as many 1s as 0s\n",
    "num_one_targets = int(np.sum(targets_all))\n",
    "zero_targets_counter = 0\n",
    "indices_to_remove = []\n",
    "\n",
    "# Collects the indices of zeros to remove\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i] == 0:\n",
    "        zero_targets_counter += 1\n",
    "        if zero_targets_counter > num_one_targets:\n",
    "            indices_to_remove.append(i)\n",
    "            \n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis = 0)\n",
    "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the inputs\n",
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "train_samples_count = int(0.8 * samples_count)\n",
    "validation_samples_count = int(0.1 * samples_count)\n",
    "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
    "\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
    "validation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count + validation_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count + validation_samples_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 - 0s - loss: 0.6663 - accuracy: 0.5826 - val_loss: 0.5550 - val_accuracy: 0.8000\n",
      "Epoch 2/100\n",
      "3/3 - 0s - loss: 0.6232 - accuracy: 0.6736 - val_loss: 0.5054 - val_accuracy: 0.9333\n",
      "Epoch 3/100\n",
      "3/3 - 0s - loss: 0.5876 - accuracy: 0.7190 - val_loss: 0.4650 - val_accuracy: 0.9667\n",
      "Epoch 4/100\n",
      "3/3 - 0s - loss: 0.5554 - accuracy: 0.7645 - val_loss: 0.4281 - val_accuracy: 0.9333\n",
      "Epoch 5/100\n",
      "3/3 - 0s - loss: 0.5254 - accuracy: 0.7934 - val_loss: 0.3959 - val_accuracy: 0.9333\n",
      "Epoch 6/100\n",
      "3/3 - 0s - loss: 0.5005 - accuracy: 0.8017 - val_loss: 0.3669 - val_accuracy: 0.9333\n",
      "Epoch 7/100\n",
      "3/3 - 0s - loss: 0.4753 - accuracy: 0.8223 - val_loss: 0.3408 - val_accuracy: 0.9333\n",
      "Epoch 8/100\n",
      "3/3 - 0s - loss: 0.4544 - accuracy: 0.8223 - val_loss: 0.3164 - val_accuracy: 0.9333\n",
      "Epoch 9/100\n",
      "3/3 - 0s - loss: 0.4356 - accuracy: 0.8306 - val_loss: 0.2949 - val_accuracy: 0.9667\n",
      "Epoch 10/100\n",
      "3/3 - 0s - loss: 0.4168 - accuracy: 0.8388 - val_loss: 0.2769 - val_accuracy: 0.9667\n",
      "Epoch 11/100\n",
      "3/3 - 0s - loss: 0.4001 - accuracy: 0.8388 - val_loss: 0.2612 - val_accuracy: 0.9667\n",
      "Epoch 12/100\n",
      "3/3 - 0s - loss: 0.3854 - accuracy: 0.8471 - val_loss: 0.2469 - val_accuracy: 0.9667\n",
      "Epoch 13/100\n",
      "3/3 - 0s - loss: 0.3719 - accuracy: 0.8430 - val_loss: 0.2349 - val_accuracy: 0.9667\n",
      "Epoch 14/100\n",
      "3/3 - 0s - loss: 0.3601 - accuracy: 0.8512 - val_loss: 0.2256 - val_accuracy: 0.9667\n",
      "Epoch 15/100\n",
      "3/3 - 0s - loss: 0.3482 - accuracy: 0.8512 - val_loss: 0.2176 - val_accuracy: 0.9667\n",
      "Epoch 16/100\n",
      "3/3 - 0s - loss: 0.3381 - accuracy: 0.8595 - val_loss: 0.2119 - val_accuracy: 0.9667\n",
      "Epoch 17/100\n",
      "3/3 - 0s - loss: 0.3296 - accuracy: 0.8554 - val_loss: 0.2076 - val_accuracy: 0.9667\n",
      "Epoch 18/100\n",
      "3/3 - 0s - loss: 0.3206 - accuracy: 0.8636 - val_loss: 0.2041 - val_accuracy: 0.9667\n",
      "Epoch 19/100\n",
      "3/3 - 0s - loss: 0.3128 - accuracy: 0.8678 - val_loss: 0.2018 - val_accuracy: 0.9667\n",
      "Epoch 20/100\n",
      "3/3 - 0s - loss: 0.3056 - accuracy: 0.8719 - val_loss: 0.2001 - val_accuracy: 0.9667\n",
      "Epoch 21/100\n",
      "3/3 - 0s - loss: 0.2986 - accuracy: 0.8719 - val_loss: 0.1993 - val_accuracy: 0.9667\n",
      "Epoch 22/100\n",
      "3/3 - 0s - loss: 0.2922 - accuracy: 0.8760 - val_loss: 0.1989 - val_accuracy: 0.9667\n",
      "Epoch 23/100\n",
      "3/3 - 0s - loss: 0.2871 - accuracy: 0.8802 - val_loss: 0.2002 - val_accuracy: 0.9333\n",
      "Epoch 24/100\n",
      "3/3 - 0s - loss: 0.2817 - accuracy: 0.8843 - val_loss: 0.2011 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f985277e5b0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model - outlines, optimizers, loss, early stopping and training\n",
    "\n",
    "# Setting the output size\n",
    "output_size = 2\n",
    "\n",
    "# Setting the size of our hidden later\n",
    "hidden_layer_size = 50\n",
    "\n",
    "# defining how our model will look like\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), \n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), \n",
    "    tf.keras.layers.Dense(output_size, activation='softmax') \n",
    "])\n",
    "\n",
    "\n",
    "# Choosing the optimizer and loss function\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setting batch size and the maximum number of epochs\n",
    "batch_size = 100\n",
    "max_epochs = 100\n",
    "\n",
    "# An early stopping mechanism to not allow overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "# fit the model\n",
    "model.fit(train_inputs, \n",
    "          train_targets,  \n",
    "          batch_size=batch_size, \n",
    "          epochs=max_epochs, \n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(validation_inputs, validation_targets),\n",
    "          verbose = 2\n",
    "          )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 878us/step - loss: 0.6920 - accuracy: 0.7419\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.69. Test accuracy: 74.19%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 56\n",
    "Data means information stored in the form of symbols. Ones and zeros other digits letters special characters etc..\n",
    "\n",
    "Where can you find data? Data today is stored practically in databases. A database is an electronic collection of data or a structure filled with information organized in a way that is easy to access manage and update. Where are databases sored? In database servers. A server is a combination of hardware and software responsible for storing managing and processing large amounts of data. The most common types are the web srvers database servers and servers.\n",
    "The client server model where servers exist to respond to the requests made by a client. A server is always a combination of hardware and software and it is related to storing managing and processing data.\n",
    "\n",
    "\n",
    "Developing and maintaining data connectivity is one of the most important things of all in regards to the ability to connect clients in servers securing the swift and voluminous transfer of information between them. Unprecedented amounts of data are being sent from servers to clients and vice versa and if it wasn't for data connectivity this wouldn't have been possible. How can one connect information from multiple servers? By using API application programming interfaces, APIs are the software tool that makes this entire picture a reality.\n",
    "Technically an API is a contract allowing software to share data with each other. Software apps in their capacity of clients need access to specific types of data contained in some servers. developers and software engineers  are the end users of the API which allow\n",
    "Apart from access to such information servers contain and provide specific software products to the term comprising the types of information you could obtain from a server is data assets. a data asset is  data that is expected to have some value in the future. Everyday examples include intellectual property such as patents or a song you composed. in API, Application refers to a program designed to perform a specific set of operations for the end user bita person or another application. API acts pretty much like a messenger.\n",
    "\n",
    "\n",
    "Looking at it from developers perspective the goal is to create apps that respond to people's needsbetter than those developed by competitors.A better app in general is one that works faster and more efficiently to achieve this.\n",
    "It needs information from multiple servers so that its end users can get rich and to the point dataas swiftly as possible.Thats why when creating the app the software developers job includes leveraging multiple API simultaneously thus employing other technologies in its core functionality. Remember the application programming interface is not the web page or the app, it is a separate technology acting as a gateway to the server which you as a programmer can connec to. an API is a collection of endpoints and they practically split its functionality into parts. Therefore a programmer will match his code with the desired in a point only. And from a technical perspective the most amazing thing about API is is that sometimes everything you need can be accessed with the ease of writing just two lines of code. An API does require maintenance and this naturally costs a certain amount of resources. security is a big problem for these interfaces. API must act as a filter that will prevent the system from malicious programmers and overloading. If you are maintaining an app and providing specific services to other apps or people in certain cases\n",
    "you should build your own API on your server to improve the communication with them.\n",
    "\n",
    "\n",
    "Software can be written in any of the hundreds of programming languages out there. when working with APIs you don't use your web browser to ask a web server for a web page. You use a software application to request specific data from a server and this data will be returned in a text format on a technical level. It is turned into ones and zeros the most universally accepted text file formats are XML, CSV and JSON. If you want to pull a data table from a SQL database stored on an external server and you want to extract it using Python you'll need to write specific lines of Python code that will let you access data from the remote server through the servers API. Instead of Python you can use a programming language such as R or Matlab to talk to an API. server will have provided the data you need without a problem.\n",
    "\n",
    "There's one other term that stems from the communication ability of programming languages and it is integration. It has two main distinguishable meanings. The first one regards having a system or an architecture composed of a few different software products various programming languages or other pieces of software which can communicate with each other via APis or a common API. The second meaning of the term integration is the more classical one which refers to a situation where multiple software products can be set up to work as one tool. However the two software products can interact. integration can happen online or locally."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
